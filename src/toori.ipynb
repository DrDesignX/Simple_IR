{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/f2yw3cln5174grx76c3nskwh0000gn/T/ipykernel_50197/2333235116.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  tf_array[r, c] = 1 + np.log10([tf_array[r, c]])\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "dictionary = []\n",
    "\n",
    "dataset_path = \"/Users/mohamad/Documents/GitHub/BrainQuest/data/documents/Cranfield collection/cran.all.1400\"\n",
    "\n",
    "# read the cran.all.1400 file that contain the all of the datasets\n",
    "try:\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        raw_dataset = f.read()\n",
    "except IOError:\n",
    "    print(\"The file does not exist, or the entered path is invalid!\")\n",
    "\n",
    "raw_dataset = raw_dataset.split(\".I\") # split the docs by index\n",
    "raw_dataset.remove(raw_dataset[0]) # remove the empty first index\n",
    "\n",
    "doc_index = 0\n",
    "for doc in raw_dataset:\n",
    "    doc_index += 1\n",
    "    doc_path = \"/Users/mohamad/Documents/GitHub/BrainQuest/data/documents/\" + \"/doc\" + str(doc_index) + \".txt\"\n",
    "    if os.path.exists(doc_path): # if file exist ignore\n",
    "        pass\n",
    "    else:\n",
    "        with open(doc_path, \"w\") as document: # write each index into the separated doc\n",
    "            document.write(doc)\n",
    "\n",
    "# read the list of stop words\n",
    "stopword_file_path = \"/Users/mohamad/Documents/GitHub/BrainQuest/data/stopword/words.txt\"\n",
    "with open(stopword_file_path, \"r\") as file:\n",
    "    stop_words = file.read()\n",
    "    \n",
    "# separate the doc section from the document\n",
    "def transfer_to_list(doc):\n",
    "    start = doc.find(\".W\")\n",
    "    doc = doc[start + 2:]\n",
    "    doc = doc.split()\n",
    "    return doc\n",
    "\n",
    "# stemming\n",
    "stemmer = PorterStemmer()\n",
    "dictionary = []\n",
    "def create_dictionary(doc, dictionary):\n",
    "    for element in doc:\n",
    "        if element.isalpha():\n",
    "            stem_word = stemmer.stem(element)\n",
    "            if (stem_word not in stop_words) and (stem_word not in dictionary):\n",
    "                dictionary.append(stem_word)\n",
    "        \n",
    "# read each doc and pass them through the methods\n",
    "for num in range(1, doc_index + 1):\n",
    "    doc_path = \"/Users/mohamad/Documents/GitHub/BrainQuest/data/documents\" + \"/doc\" + str(num) + \".txt\"\n",
    "    with open(doc_path, \"r\") as file:\n",
    "        doc = file.read()\n",
    "        doc = transfer_to_list(doc)\n",
    "        create_dictionary(doc, dictionary)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# initializing the numpy arrays\n",
    "tf_array = np.zeros((len(dictionary), doc_index))\n",
    "idf_array = np.zeros((len(dictionary), 1))\n",
    "tf_idf_array = np.zeros((len(dictionary), doc_index))\n",
    "\n",
    "\n",
    "def calculate_term_frequency(doc, dictionary, doc_no):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            frequency = doc.count(word)\n",
    "            row = dictionary.index(word)\n",
    "            column = doc_no - 1\n",
    "            tf_array[row, column] += frequency\n",
    "\n",
    "\n",
    "def calculate_inverse_document_frequency(doc, dictionary):\n",
    "    for word in dictionary:\n",
    "        if word in doc:\n",
    "            row = dictionary.index(word)\n",
    "            idf_array[row, 0] += 1\n",
    "    \n",
    "    \n",
    "# extract the text from each document\n",
    "def extract_the_text(doc):\n",
    "    start = doc.find(\".W\")\n",
    "    doc = doc[start + 2:]\n",
    "    return doc\n",
    "\n",
    "doc_names_list = []\n",
    "for num in range(1, doc_index + 1):\n",
    "    doc_path = \"/Users/mohamad/Documents/GitHub/BrainQuest/data/documents\" + \"/doc\" + str(num) + \".txt\"\n",
    "    doc_names_list.append(\"doc\" + str(num) + \".txt\")\n",
    "    with open(doc_path, \"r\") as file:\n",
    "        doc = file.read()\n",
    "        doc = extract_the_text(doc)\n",
    "        calculate_term_frequency(doc, dictionary, num)\n",
    "        calculate_inverse_document_frequency(doc, dictionary)\n",
    "\n",
    "# calculating tf array\n",
    "row, column = np.shape(tf_array)\n",
    "for r in range(row):\n",
    "    for c in range(column):\n",
    "        if tf_array[r, c] > 0:\n",
    "            tf_array[r, c] = 1 + np.log10([tf_array[r, c]])\n",
    "        else:\n",
    "            tf_array[r, c] = 1\n",
    "\n",
    "count_of_documents = column\n",
    "row, column = np.shape(idf_array)\n",
    "\n",
    "\n",
    "# calculating idf array\n",
    "for r in range(row):\n",
    "    if idf_array[r, 0] > 0:\n",
    "        idf_array[r, 0] = np.log10(count_of_documents / idf_array[r, 0])\n",
    "    else:\n",
    "        idf_array[r, 0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
      "experiment  1.477121       1.0       1.0       1.0       1.0       1.0   \n",
      "investig    1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "aerodynam   1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "slipstream  1.698970       1.0       1.0       1.0       1.0       1.0   \n",
      "studi       1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "squir       1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "standoff    1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "hoshizaki   1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "recover     1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "fralich     1.000000       1.0       1.0       1.0       1.0       1.0   \n",
      "\n",
      "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
      "experiment       1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "investig         1.0       1.0  1.477121        1.0  ...          1.0   \n",
      "aerodynam        1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "slipstream       1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "studi            1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "...              ...       ...       ...        ...  ...          ...   \n",
      "squir            1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "standoff         1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "hoshizaki        1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "recover          1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "fralich          1.0       1.0  1.000000        1.0  ...          1.0   \n",
      "\n",
      "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
      "experiment          1.0          1.0          1.0          1.0          1.0   \n",
      "investig            1.0          1.0          1.0          1.0          1.0   \n",
      "aerodynam           1.0          1.0          1.0          1.0          1.0   \n",
      "slipstream          1.0          1.0          1.0          1.0          1.0   \n",
      "studi               1.0          1.0          1.0          1.0          1.0   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "squir               1.0          1.0          1.0          1.0          1.0   \n",
      "standoff            1.0          1.0          1.0          1.0          1.0   \n",
      "hoshizaki           1.0          1.0          1.0          1.0          1.0   \n",
      "recover             1.0          1.0          1.0          1.0          1.0   \n",
      "fralich             1.0          1.0          1.0          1.0          1.0   \n",
      "\n",
      "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
      "experiment          1.0          1.0          1.0          1.0  \n",
      "investig            1.0          1.0          1.0          1.0  \n",
      "aerodynam           1.0          1.0          1.0          1.0  \n",
      "slipstream          1.0          1.0          1.0          1.0  \n",
      "studi               1.0          1.0          1.0          1.0  \n",
      "...                 ...          ...          ...          ...  \n",
      "squir               1.0          1.0          1.0          1.0  \n",
      "standoff            1.0          1.0          1.0          1.0  \n",
      "hoshizaki           1.0          1.0          1.0          1.0  \n",
      "recover             1.0          1.0          1.0          1.0  \n",
      "fralich             1.0          1.0          1.0          1.0  \n",
      "\n",
      "[3441 rows x 1400 columns]\n",
      "                 IDF\n",
      "experiment  0.538673\n",
      "investig    0.586221\n",
      "aerodynam   0.886057\n",
      "slipstream  1.970037\n",
      "studi       1.063343\n",
      "...              ...\n",
      "squir       2.845098\n",
      "standoff    2.845098\n",
      "hoshizaki   3.146128\n",
      "recover     1.714764\n",
      "fralich     3.146128\n",
      "\n",
      "[3441 rows x 1 columns]\n",
      "            doc1.txt  doc2.txt  doc3.txt  doc4.txt  doc5.txt  doc6.txt  \\\n",
      "experiment  0.795685  0.538673  0.538673  0.538673  0.538673  0.538673   \n",
      "investig    0.586221  0.586221  0.586221  0.586221  0.586221  0.586221   \n",
      "aerodynam   0.886057  0.886057  0.886057  0.886057  0.886057  0.886057   \n",
      "slipstream  3.347033  1.970037  1.970037  1.970037  1.970037  1.970037   \n",
      "studi       1.063343  1.063343  1.063343  1.063343  1.063343  1.063343   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "squir       2.845098  2.845098  2.845098  2.845098  2.845098  2.845098   \n",
      "standoff    2.845098  2.845098  2.845098  2.845098  2.845098  2.845098   \n",
      "hoshizaki   3.146128  3.146128  3.146128  3.146128  3.146128  3.146128   \n",
      "recover     1.714764  1.714764  1.714764  1.714764  1.714764  1.714764   \n",
      "fralich     3.146128  3.146128  3.146128  3.146128  3.146128  3.146128   \n",
      "\n",
      "            doc7.txt  doc8.txt  doc9.txt  doc10.txt  ...  doc1391.txt  \\\n",
      "experiment  0.538673  0.538673  0.538673   0.538673  ...     0.538673   \n",
      "investig    0.586221  0.586221  0.865920   0.586221  ...     0.586221   \n",
      "aerodynam   0.886057  0.886057  0.886057   0.886057  ...     0.886057   \n",
      "slipstream  1.970037  1.970037  1.970037   1.970037  ...     1.970037   \n",
      "studi       1.063343  1.063343  1.063343   1.063343  ...     1.063343   \n",
      "...              ...       ...       ...        ...  ...          ...   \n",
      "squir       2.845098  2.845098  2.845098   2.845098  ...     2.845098   \n",
      "standoff    2.845098  2.845098  2.845098   2.845098  ...     2.845098   \n",
      "hoshizaki   3.146128  3.146128  3.146128   3.146128  ...     3.146128   \n",
      "recover     1.714764  1.714764  1.714764   1.714764  ...     1.714764   \n",
      "fralich     3.146128  3.146128  3.146128   3.146128  ...     3.146128   \n",
      "\n",
      "            doc1392.txt  doc1393.txt  doc1394.txt  doc1395.txt  doc1396.txt  \\\n",
      "experiment     0.538673     0.538673     0.538673     0.538673     0.538673   \n",
      "investig       0.586221     0.586221     0.586221     0.586221     0.586221   \n",
      "aerodynam      0.886057     0.886057     0.886057     0.886057     0.886057   \n",
      "slipstream     1.970037     1.970037     1.970037     1.970037     1.970037   \n",
      "studi          1.063343     1.063343     1.063343     1.063343     1.063343   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "squir          2.845098     2.845098     2.845098     2.845098     2.845098   \n",
      "standoff       2.845098     2.845098     2.845098     2.845098     2.845098   \n",
      "hoshizaki      3.146128     3.146128     3.146128     3.146128     3.146128   \n",
      "recover        1.714764     1.714764     1.714764     1.714764     1.714764   \n",
      "fralich        3.146128     3.146128     3.146128     3.146128     3.146128   \n",
      "\n",
      "            doc1397.txt  doc1398.txt  doc1399.txt  doc1400.txt  \n",
      "experiment     0.538673     0.538673     0.538673     0.538673  \n",
      "investig       0.586221     0.586221     0.586221     0.586221  \n",
      "aerodynam      0.886057     0.886057     0.886057     0.886057  \n",
      "slipstream     1.970037     1.970037     1.970037     1.970037  \n",
      "studi          1.063343     1.063343     1.063343     1.063343  \n",
      "...                 ...          ...          ...          ...  \n",
      "squir          2.845098     2.845098     2.845098     2.845098  \n",
      "standoff       2.845098     2.845098     2.845098     2.845098  \n",
      "hoshizaki      3.146128     3.146128     3.146128     3.146128  \n",
      "recover        1.714764     1.714764     1.714764     1.714764  \n",
      "fralich        3.146128     3.146128     3.146128     3.146128  \n",
      "\n",
      "[3441 rows x 1400 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_dictionary(doc, dictionary):\n",
    "    for element in doc:\n",
    "        if element.isalpha():\n",
    "            stem_word = stemmer.stem(element)\n",
    "            if (stem_word not in stop_words) and (stem_word not in dictionary):\n",
    "                dictionary.append(stem_word)\n",
    "\n",
    "\n",
    "# multiply peer to peer each row of tf-array in idf-array\n",
    "row, column = np.shape(tf_idf_array)\n",
    "for r in range(row):\n",
    "    for c in range(column):\n",
    "        tf_idf_array[r, c] = tf_array[r, c] * idf_array[r, 0]\n",
    "\n",
    "\n",
    "# function to create the excel files\n",
    "def create_excel(input , name, columns, index):\n",
    "    df = pd.DataFrame(input, columns = columns, index = index) # Create a pandas dataframe\n",
    "    df.to_excel(name) # Create an excel file\n",
    "    print(df)\n",
    "    \n",
    "\n",
    "create_excel(tf_array, \"tf_excel.xlsx\", doc_names_list, dictionary)\n",
    "create_excel(idf_array, \"idf_excel.xlsx\", [\"IDF\"], dictionary)\n",
    "create_excel(tf_idf_array, \"tf_idf_excel.xlsx\", doc_names_list, dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
